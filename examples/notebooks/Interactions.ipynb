{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3be78c4-1f40-4856-837d-0269bf6d0ee0",
   "metadata": {},
   "source": [
    "# Interactions\n",
    "Coba calls individual training/evaluation examples \"Interactions\". There are three types of interactions:\n",
    "```python\n",
    "1. coba.SimulatedInteraction(\n",
    "    context : Optional[Features],\n",
    "    actions : Sequence[Features], \n",
    "    rewards : Sequence[float] | Callable[[Action],float],\n",
    "    **kwargs: Any\n",
    ")\n",
    "\n",
    "2. coba.LoggedInteraction(\n",
    "    context    : Optional[Features],\n",
    "    action     : Features,\n",
    "    reward     : float,\n",
    "    probability: Optional[float],\n",
    "    **kwargs   : Any\n",
    ")\n",
    "\n",
    "3. coba.GroundedInteraction(\n",
    "    context  : Optional[Features],\n",
    "    actions  : Sequence[Features],\n",
    "    rewards  : Sequence[float] | Callable[[Action],float],\n",
    "    feedbacks: Sequence[float] | Callable[[Action],float],\n",
    "    **kwargs : Any\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "The interaction classes above are provided as type-hints. In practice interactions are nothing more than dicts. That is,\n",
    "```python\n",
    "cb.SimulatedInteraction(1,[1],[3])    == {'context':1,'actions':[1],'rewards':[3]}\n",
    "cb.LoggedInteraction(1,2,3,.5)        == {'context':1,'action':2,'reward':3,'probability':.5}\n",
    "cb.GroundedInteraction(1,[1],[3],[5]) == {'context':1,'actions':[1],'rewards':[3],'feedbacks':[5]}\n",
    "```\n",
    "\n",
    "The possible values for contexts and actions (i.e. the `Features` type hint above) are described in more detail in [Features.ipynb](Features.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ab555a-9260-42d8-b9d3-8cfbb163cce2",
   "metadata": {},
   "source": [
    "# Simulated Interaction\n",
    "Simulated interactions have full reward and action information. They can simulate the learning and outcome of any given policy.\n",
    "\n",
    "Simulated interactions must have an 'actions' and 'rewards' value. The following are examples of simulated interactions:\n",
    "\n",
    "```python\n",
    "import coba as cb\n",
    "\n",
    "# One discrete simulated interaction whose two actions have a single continuous feature\n",
    "{'actions':[1,2], 'rewards':[4,5]}\n",
    "\n",
    "# Two discrete simulated interactions whose two actions have disjoint action features\n",
    "{'actions':['a','b']    , 'rewards':[0,1]}\n",
    "{'actions':[(1,0),(0,1)], 'rewards':[0,1]}\n",
    "\n",
    "# Two discrete simulated interactions whose two actions have sparse features\n",
    "{'actions':[['a','b'],['c','d']]           , 'rewards':[0,1]}\n",
    "{'actions':[{'a':1, 'b':1}, {'c':1, 'd':1}], 'rewards':[0,1]}\n",
    "\n",
    "# One continuous simulated interaction. It is up to the learner to know the actions\n",
    "{'actions':None, 'rewards':cb.L1Reward(2)}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c66092-2241-402e-b6f3-f1bd61885f25",
   "metadata": {},
   "source": [
    "# Logged Interaction\n",
    "Logged interactions contain data that was logged during an online interaction. They can be used for off-policy analysis.\n",
    "\n",
    "Logged interactions must have an 'action' and 'reward' value. The following are examples of logged interactions:\n",
    "\n",
    "```python\n",
    "import coba as cb\n",
    "\n",
    "# One logged interaction whose action is a single continuous feature and without probability information\n",
    "{'context': 1, 'action':1, 'reward':4}\n",
    "\n",
    "# One logged interaction whose action is a single continuous feature and with probability information\n",
    "{'context': 1, 'action':1, 'reward':4, 'probability':.1}\n",
    "\n",
    "# Two logged intreactions whose actions have a single categorical feature\n",
    "{'context': 1, 'action':'a'  , 'reward':0}\n",
    "{'context': 1, 'action':(1,0), 'reward':0}\n",
    "\n",
    "# Two logged interactions whose actions have sparse features\n",
    "{'action':['a','b']     , 'rewards':1}\n",
    "{'action':{'a':1, 'b':1}, 'rewards':1}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f57e86-a9a7-488a-a7d6-435126e733a6",
   "metadata": {},
   "source": [
    "# Logged and Simulated Interaction\n",
    "\n",
    "Because the kind of interaction is determined by the dictionary keys it is possible to have an interaction that is both logged and simulated.\n",
    "\n",
    "For example, by applying a logging policy to a simulated interaction we can add logged interaction data as well:\n",
    "```python\n",
    "{'actions':[1,2], 'rewards':[4,5], 'action':2, 'reward':5, 'probability':.5}\n",
    "```\n",
    "\n",
    "This kind of interaction is particularly useful for off-policy analysis because we can compare against on-policy methods as well.\n",
    "\n",
    "The easiest way to create this data is to apply the logged filter to simulated interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71b20427-2bbb-4ece-a8a2-f53aa5b906da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "First simulated interaction in the environment\n",
      "----------------------------------------------\n",
      "  {'context': [-0.75], 'actions': [[-0.59], [0.95]], 'rewards': [0.82, -0.05]}\n",
      "\n",
      "----------------------------------------------\n",
      "First logged interaction using logging policy\n",
      "----------------------------------------------\n",
      "  {'context': [-0.75], 'actions': [[-0.59], [0.95]], 'rewards': [0.82, -0.05], 'action': [-0.59], 'probability': 0.5, 'reward': 0.82}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "logging_policy = cb.RandomLearner()\n",
    "\n",
    "sim = cb.Environments.from_linear_synthetic(100, n_actions=2, n_context_features=1, n_action_features=1)\n",
    "log = sim.logged(logging_policy)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"First simulated interaction in the environment\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"  \",end=\"\")\n",
    "print(cb.minimize(next(sim[0].read()),2))\n",
    "\n",
    "print()\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"First logged interaction using logging policy\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"  \",end=\"\")\n",
    "print(cb.minimize(next(log[0].read()),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ef4979-b34d-4a9f-99c8-7745ce5019d0",
   "metadata": {},
   "source": [
    "# Grounded Interaction\n",
    "\n",
    "Grounded interactions exist to support [Interaction Grounded Learning](https://proceedings.mlr.press/v139/xie21e.html) experiments.\n",
    "\n",
    "Grounded interactions must have 'actions', 'rewards', 'feedbacks', and 'userid'. They can be created from simulated interactions using `grounded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d45a1ef-8229-4500-b258-c705a0655688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "First simulated interaction\n",
      "----------------------------------------------\n",
      "  {'context': [-0.74531], 'actions': [[-0.59205], [0.94641]], 'rewards': [0.8204, -0.05007]}\n",
      "\n",
      "----------------------------------------------\n",
      "First grounded interaction from simulated\n",
      "----------------------------------------------\n",
      "  {'context': [-0.74531], 'actions': [[-0.59205], [0.94641]], 'rewards': BinaryReward([-0.59205]), 'feedbacks': GroundedFeedback([-0.59205]), 'userid': 0, 'isnormal': True}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "sim = cb.Environments.from_linear_synthetic(100, n_actions=2, n_context_features=1, n_action_features=1)\n",
    "grd = sim.grounded(5,1,20,2)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"First simulated interaction\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"  \",end=\"\")\n",
    "print(cb.minimize(next(sim[0].read()),5))\n",
    "\n",
    "print()\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"First grounded interaction from simulated\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"  \",end=\"\")\n",
    "print(cb.minimize(next(grd[0].read()),5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
